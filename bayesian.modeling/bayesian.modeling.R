##------------------------------------------------------------##
## Contains the code and documentation for the main functions
## of the bayesian.modeling package.
##------------------------------------------------------------##




##-----------------------------------##
##-- OVERALL PACKAGE DOCUMENTATION --##
##-----------------------------------##

#'@title Tools for bayesian analysis of epidemiologic models
#'@description Implements a sampling/importance-resampling algorithm for bayesian analysis of epidemiologic models
#'
#'In general, use of this package will follow these steps:\enumerate{
#'\item A call to \code{\link{prepare.distributed.sampling}} to set up the initial sampling. This function outputs a number of batch scripts to actually run the samples \cr
#'   *To add more samples than were set up initially, use \code{\link{augment.distributed.samples}} one or more times
#'\item Running the samples by either (1) separately running the batch scripts generated by \code{\link{prepare.distributed.sampling}} (which allows the samples to be run in parallel) or (2) calling \code{\link{run.distributed.samples}} (which runs the samples in series)
#'\item A call to \code{\link{resample.distributed.samples}} to perform the importance resampling
#'\item One or more calls to \code{\link{perform.inference.on.resample}} to extract output parameters. The output of this function is an instance of \code{\link{Empiric.Distribution-class}}
#'}
#'
#'@details Some Tips:\itemize{
#'\item To quickly look at prior and posterior distributions of input parameters, use \code{\link{get.parameters.prior}} and \code{\link{get.parameters.posterior}} along with \code{\link{plot.distributions}}
#'\item For how to manipulate the final results (which are instances of \code{\link{Empiric.Distribution-class}}) look at the documentation on \code{\link{Empiric.Distribution-class}}
#'\item Use \code{\link{Joint.Canonical.Distribution-class}} to quickly specify how to generate input parameters
#'}
#'
#'@docType package
#'@name bayesian.modeling
NULL








##----------------------------------------------------------##
##-- THE INITIAL SAMPLING / AUGMENTING THE INITIAL SAMPLE --##
##----------------------------------------------------------##

#'@title Prepare to run a a number of samples through a model in a distributed fashion
#'
#'@description Prepares batch scripts that will run a model <num.samples> times in <num.chunks> separate processes. The input parameters for each run of the model are generated by Latin hypercube sampling
#'
#'@param directory The directory where intermediate files should be stored
#'@param num.samples The total number of samples to run
#'@param num.chunks The number of separate batches ('chunks') to run (ie, if num.samples is 120 and num.chunks is 10, we will set up to run 10 processes, with each process running the model 12 times). Alternatively, this argument  can be set to NA, and the argument num.samples.per.chunk can be specified
#'@param num.input.parameters The number of input parameters taken by the model
#'@param generate.input.parameters A way to map a vector of quantiles [0,1] to a vector of input parameters. Can take either (1) an instance of \code{\link{Joint.Canonical.Distribution-class}} or (2) a function which takes as its argument a vector of length num.input.parameters of quantiles and returns a vector representing input parameters to the model. For independently distributed input parameters, each element of the return value should be the appropriate quantile function on the corresponding element of the argument vector
#'@param run.model A function which takes as its first argument a vector of input parameters. It should return some object representing the model result, which can be passed to calculate.likelihood and get.output.parameters
#'@param ... Other parameters to be passed to generate.input.parameters and run.model
#'@param num.samples.per.chunk If num.chunks is set to NA, then this argument is used to pick num.chunks so that each chunk has no more than num.samples.per.chunk runs of the model
#'@param files.to.source A vector of filenames; source will be called on these files prior to running generate.input.paramters, run.model, or d.input.parameter.generator
#'@param d.input.parameter.generator A way to map a vector of input parameters to the probability that those parameters were generated by 'generate.input.parameters'. Can be either (1) an instance of a \code{\link{Joint.Canonical.Distribution-class}}, (2) a function that takes a set of input parameters and returns the density by which they were generated, (3) omitted (if 'generate.input.parameters' is an instance of \code{\link{Joint.Canonical.Distribution-class}}, that will be used to fill in this argument's value\cr
#'This parameter will only be used if input parameters will generated according to a distribution different from their prior distribution (ie, if you want to more heavily sample some areas of the parameter space or after-the-fact change the prior distribution on parameters); if input parameters will be sampled according to their priors, then this argument may be omitted\cr
#'This parameter can be set or overwritten later with a subsequent call to \code{\link{set.d.input.parameter.generator}}
#'@param seed Seed for the random number generator
#'@inheritParams write.batch.scripts
#'
#'@details In general, the batch scripts may be in one of two forms:\itemize{
#'\item In the simpler method, the main batch script directly calls Rscript multiple times to execute the .R script that actually runs a sample through the model. This is achieved by specifying the rscript.call argument, but passing NULL for the master.batch.prefix argument
#'\item In the more complicated, or 'nested' method, two sets of batch scripts are created. The main batch script calls a 'wrapper' batch script for each separate execution of the .R script. In this case, master.batch.prefix and master.batch.postfix are used to specify how the master batch file calls each wrapper batch file, and rscript.call / rscript.call.postfix are used in each wrapper batch file to actually call the .R script
#'}
#'Generally, the second method will be preferred, as it is useful for queueing tasks on a remote machine.\cr
#'Either way, a master batch file 'run_all' is created in the specified directory that, when called, will execute all the individual samples\cr
#'\cr
#'To add additional samples once this function has already been called (while preserving the Latin hypercube properties of the input parameters, use \code{\link{augment.distributed.sampling}})\cr
#'To rewrite the batch scripts (in case there is a change or an error in the original call), use \code{\link{write.batch.scripts}}
#'
#'
#'@examples
#'#Say we have three input parameters, p1 which follows a normal(2,1) distribution,
#'# p2 which follows a uniform(-1,1), and p3 which follows a beta(2,2)
#'
#'param.dist = Joint.Canonical.Distribution('norm',2,1,'unif',-1,1,'beta',2,2,var.names=c('p1','p2','p3'))
#'
#'run.the.model <- function(input.parameters, other.data.to.run.model)
#'{
#'  #actually run the model
#'  return (model.results)
#'}
#'
#'#We prepare to take 10,000 samples in 200 chunks (each chunk will thus contain 50 samples)
#'prepare.distributed.sampling('mydirectory',
#'                              num.samples = 10000,
#'                              num.chunks = 200,
#'                              generate.input.parameters = param.dist,
#'                              run.model = run.the.model,
#'                              rscript.call='Rscript',
#'                              master.batch.prefix="qsub -l mem_free=10G",
#'                              other.data.to.run.the.model,
#'                              files.to.source='source.code.for.running.model.R')
#'
#'#Running the batch script 'run_all.sh' will now queue up 200 different processes
#'# with qsub, each process will run 50 different samples
#'# (qsub is a command for queueing a task on a cluster; in this case, we specify
#'#  that the job should be queued to a machine with at least 10G of memory free)
#'
#'@return Has no return value. However, it writes batch scripts to the given directory. When called, these batch scrips will execute all the sample runs in parallel:\itemize{
#'\item 'run_all.sh' 
#'\item 'run_<group number>.sh'
#'\item 'run_unfinished.sh' 
#'}
#'@seealso \code{\link{augment.distributed.sampling}}\cr
#'\code{\link{write.batch.scripts}}\cr
#'\code{\link{resample.distributed.sample}}\cr
#'\code{\link{Joint.Canonical.Distribution-class}}
#'
#'@export
prepare.distributed.sampling <- function(directory,
                                         num.samples,
                                         num.chunks = NA,
                                         num.input.parameters,
                                         generate.input.parameters,
                                         run.model,
                                         rscript.call='Rscript',
                                         ...,
                                         num.samples.per.chunk = NA,
                                         rscript.call.postfix = NULL,
                                         master.batch.prefix = NULL,
                                         master.batch.postfix = NULL,
                                         batch.extension='sh',
                                         files.to.source = NULL,
                                         d.input.parameter.generator = NULL,
                                         use.absolute.paths = T,
                                         seed=11111)
{
    controller = list()
    controller$run.model = run.model
    if (class(generate.input.parameters) == 'Joint.Canonical.Distribution')
    {
        if (is.null(d.input.parameter.generator))
            d.input.parameter.generator = generate.input.parameters
        generate.input.parameters = quantiles.function(generate.input.parameters)
    }
    controller$generate.input.parameters = generate.input.parameters
    controller$num.input.parameters = num.input.parameters
    if (class(d.input.parameter.generator)=='Joint.Canonical.Distribution')
        d.input.parameter.generator = density.function(d.input.parameter.generator)
    controller$d.input.parameter.generator = d.input.parameter.generator
    
    controller$input.parameter.sets = NULL
    controller$input.parameter.quantiles = NULL
    
    controller$chunks = NULL
    
    controller$groups = list()
    
    controller$dotdotdot = list(...)
    controller$files.to.source = files.to.source
    controller$use.absolute.paths = use.absolute.paths
    
    throwaway = do.prepare.sampling(controller, directory, num.samples, num.chunks, num.samples.per.chunk, seed=seed)
    reset.distributed.sampling(directory)
    
    print(paste0("...done. A batch file has been created in '", directory, "':"))
    do.save.batch.info.and.write.scripts(directory, rscript.call, rscript.call.postfix, master.batch.prefix, master.batch.postfix, batch.extension, use.absolute.paths)
    do.print.batch.summary(controller, show.unfinished = F)
}

#'@title Prepare extra samples to be run in addition to some previously prepared samples
#'
#'@description A function to be used to add additional samples, after a set of samples has already been set up by a call to \code{\link{prepare.distributed.sampling}}. This function may be called multiple times
#'
#'@param directory The directory that was previously given to a call to \code{\link{prepare.distributed.sampling}}
#'@param num.samples The total number of additional samples to run
#'@param num.chunks The number of separate batches ('chunks') to run the added samples in (ie, if num.samples is 120 and num.chunks is 10, we will set up to run 10 processes, with each process running the model 12 times). Alternatively, this argument  can be set to NA, and the argument num.samples.per.chunk can be specified
#'@param num.samples.per.chunk If num.chunks is set to NA, then this argument is used to pick num.chunks so that each chunk has no more than num.samples.per.chunk runs of the model
#'@param seed Seed for the random number generator
#'
#'@return Returns a 'group' number corresponding to the samples added by this function call (eg, if we had one call to prepare.distributed.sampling previously, this function call would return 2). More importantly, this function creates several batch scripts: "run_all.sh" will run all the distributed samples (both those set up previously and those set up by this function). "run_unfinished.sh" will only run the samples that have not already been run. "run_<group>.sh" where group is the number returned by the function will run just the sample added by this call to the function. 
#'@seealso \code{\link{prepare.distributed.sampling}}\cr
#'\code{\link{write.batch.scripts}}\cr
#'\code{\link{resample.distributed.sample}}
#'
#'@export
augment.distributed.sampling <- function(directory,
                                         num.samples.to.add,
                                         num.chunks = NA,
                                         num.samples.per.chunk = NA,
                                         seed=11111)
{
    controller = load.controller(directory)
    group = do.prepare.sampling(controller, directory, num.samples.to.add, num.chunks, num.samples.per.chunk, seed=seed)

    controller = load.controller(directory)
    do.write.batch.scripts(controller, directory, groups=group)
    
    print(paste0("...done. Several batch files have been created in '", directory, "':"))
    do.print.batch.summary(controller, groups=group)
}




##The actual work of preparing for distributed sampling
do.prepare.sampling <- function(controller, 
                                directory,
                                num.samples,
                                num.chunks,
                                num.samples.per.chunk,
                                seed)
{
    set.seed(seed)
    sapply(controller$files.to.source, source)
    
    print(paste0('Generating ', num.samples, ' Latin hypercube samples...'))
    #set up the quantiles by LHS
    if (is.null(controller$input.parameter.quantiles))
        new.quantiles = randomLHS(n=num.samples, k=controller$num.input.parameters)
    else
        new.quantiles = augmentLHS(controller$input.parameter.quantiles, num.samples)
    print('...done generating Latin hypercube samples')    
    controller$input.parameter.quantiles = rbind(controller$input.parameter.quantiles)
    
    
    #map the LHS quantiles to parameters
    print('Converting Latin hypercube samples to input parameters...')
    new.parameter.sets = t(apply(new.quantiles, 1, function(x){
        do.call(controller$generate.input.parameters, c(list(x), controller$dotdotdot))
    }))
    controller$input.parameter.sets = rbind(controller$input.parameter.sets, new.parameter.sets)
    print('...done converting to input paramters')
    
    #set up the chunking
    if (is.null(controller$chunks))
        start.chunk = 1
    else
        start.chunk = max(controller$chunks) + 1
    
    if (is.na(num.chunks))
    {
        if (is.na(num.samples.per.chunk))
            num.chunks = 1
        else
            num.chunks = ceiling(num.samples/num.samples.per.chunk)
    }
    num.samples.per.chunk = ceiling(num.samples/num.chunks)
    
    num.with.fewer.samples = num.chunks * num.samples.per.chunk - num.samples
    num.with.full.samples = num.chunks - num.with.fewer.samples
    
    new.chunks = rep(1:num.with.full.samples, each=num.samples.per.chunk)
    if (num.with.fewer.samples > 0)
        new.chunks = c(new.chunks, num.with.full.samples + rep(1:num.with.fewer.samples, each=num.samples.per.chunk-1))
    new.chunks = start.chunk - 1 + new.chunks
    
    controller$chunks = c(controller$chunks, new.chunks)
    controller$num.chunks = start.chunk + num.chunks - 1
    
    #set up group
    group = length(controller$groups) + 1
    controller$groups[[group]] = c(start.chunk, start.chunk + num.chunks - 1)
    
    print("Saving and setting up batch files...")
    
    #save the controller
    save.controller(controller, directory)
    
    #write our common script
    write.script(controller, directory)

    group
}

#'@title Set the density according to which input parameters were generated
#'@description If the parameter 'd.input.parameter.generator' was not set during a call to \code{\link{prepare.distributed.sampling}}, it may be set here
#'
#'@param directory The directory that was previously given to a call to \code{\link{prepare.distributed.sampling}}
#'@inheritParams prepare.distributed.sampling
#'
#'@seealso \code{\link{Joint.Canonical.Distribution-class}}
set.d.input.parameter.generator <- function(directory, d.input.parameter.generator)
{
    controller = load.controller(directory)
    
    if (class(d.input.parameter.generator)=='Joint.Canonical.Distribution')
        d.input.parameter.generator = density.function(d.input.parameter.generator)
    controller$d.input.parameter.generator = d.input.parameter.generator
    
    save.controller(controller, directory)
}




##-----------------------##
##-- SUMMARY FUNCTIONS --##
##-----------------------##

#'@title Summarize progress on distributed sampling
#'
#'@description Prints a summary of the set-up and progress so far of a distributed sample set up by \code{\link{prepare.distributed.sampling}}
#'
#'@param directory The directory that was previously given to a call to \code{\link{prepare.distributed.sampling}}
#'@param group.details Logical indicating whether to give detailed information on the number of chunks in each group
#'
#'@export
summarize.sampling <- function(directory, group.details=F)
{
    controller = load.controller(directory)
    
    cat('-------------------------------------------------------\n')
    
    chunk.sizes = table(controller$chunks)
    if (max(chunk.sizes) == min(chunk.sizes))
        chunk.range = paste0("of ", chunk.sizes[1], " samples each")
    else
        chunk.range = paste0("ranging in size from ", min(chunk.sizes), " to ", max(chunk.sizes), " samples each")
    
    cat(paste0("'", directory, "' references a distributed sampling set-up that comprises:\n"))
    cat(paste0('-', length(controller$chunks), " samples\n"))
    cat(paste0('-Across ', length(unique(controller$chunks)), ' chunks ', chunk.range, "\n"))
    if (length(controller$groups) == 1)
    {
        groups = ' group'
        ie = 'ie, the initial sample set-up has NOT been augmented'
    }
    else
    {
        groups = ' groups'
        ie = 'ie, the initial sample set has been augmented '
        if (length(controller$groups)==2)
            ie = paste0(ie, '1 time')
        else
            ie = paste0(ie, length(controller$groups)-1, ' times')
    }
    cat(paste0('-In ', length(controller$groups), groups, ' (', ie, ")\n"))
    
    num.complete.per.group = get.num.complete.per.group(controller, directory)
    num.chunks.per.group = num.chunks.per.group(controller)
    
    cat("\n")
    
    cat(paste0('The sampling is ', round(100*sum(num.complete.per.group)/sum(num.chunks.per.group)), '% complete (', sum(num.complete.per.group), ' / ', sum(num.chunks.per.group), " chunks)\n"))
    
    if (length(controller$groups) > 1)
    {
        for (i in 1:length(controller$groups))
        {
            #            cat(paste0('-Group ', i, ' is ', round(100*num.complete.per.group[i]/num.chunks.per.group[i]), '% complete (', num.complete.per.group[i], ' / ', num.chunks.per.group[i], ' chunks)'))
            cat(paste0('-', get.group.summary(controller, directory, i, num.complete.per.group[i], num.chunks.per.group[i], details=group.details)), "\n")
        }
    }
    
    cat("\n")
    if (is.null(controller$d.input.parameter.generator))
        cat("A density according to which input parameters were generated ('d.input.parameter.generator') has NOT been specified\n")
    else
        cat("A density according to which input parameters were generated ('d.input.parameter.generator') HAS been specified\n")
    
    cat('-------------------------------------------------------\n')
}

#'@title Summarize the results of resampling
#'
#'@description Prints a summary of resamples generated by \code{\link{resample.distributed.samples}}
#'
#'@param resamples Can be either (1) An instance of \code{\link{Resamples-class}}, (2) a file where such a Resamples object is saved, or (3) a directory (such as one set up by a call to \code{link{prepare.distributed.sampling}} on which \code{\link{resample.distributed.samples}} has been called)
#'@param top.n.resamples The number of uniquely resampled samples to display details about. If 0, no details on resamples will be printed
#'
#'@export
summarize.resample <- function(resamples, detail.top.n.resamples=5)
{
    if (class(resamples)=='Resamples')
        contained.in = NULL
    else if (dir.exists(resamples))
        contained.in = paste0("the directory '", resamples, '"')
    else if (file.exists(resamples))
        contained.in = paste0("the file '", resamples, '"')
    else
        contained.in = NULL
    
    resamples = load.resamples(resamples)
    
    cat('-------------------------------------------------------\n')
    do.summarize.resamples(resamples, contained.in=contained.in, num.to.show = detail.top.n.resamples)
    cat('-------------------------------------------------------\n')
}



#helper for printing group summaries
get.group.summary <- function(controller, directory, group, num.complete=NULL, num.chunks=NULL, details=T)
{
    if (is.null(num.complete))
        num.complete = get.num.complete.per.group(controller, directory)[group]
    if (is.null(num.chunks))
        num.chunks = num.chunks.per.group(controller)[group]
    
    rv = paste0('Group ', group)
    if (details)
    {
        rv = paste0(rv, ' comprises ', num.chunks, ' chunks ')
        
        chunk.sizes = table(controller$chunks)[(controller$groups[[group]][1]):(controller$groups[[group]][2])]
        if (max(chunk.sizes) == min(chunk.sizes))
            rv = paste0(rv, "of ", chunk.sizes[1], "samples each")
        else
            rv = paste0(rv, "of ", min(chunk.sizes), " or ", max(chunk.sizes), " samples each")
        
        rv = paste0(rv, ". It")
    }
    
    rv = paste0(rv, " is ", round(100*num.complete/num.chunks), "% complete (", num.complete, " / ", num.chunks, ")")
    
    rv
}


#'@title Determine if distributed sampling is complete
#'
#'@param directory The directory specified in \code{\link{prepare.distributed.sampling}}
#'@param groups If the initial sampling has been augmented, there will be more than one group of samples. If the groups argument is specified, the function will return true if those groups are complete; if the groups argument is null, it will return true if all groups are complete
#'
#'@return True if all the distributed samples have been run, false otherwise
#'@export
is.sampling.complete <- function(directory, groups=NULL)
{
    is.sampling.complete.sub(load.controller(directory), directory, groups=groups)
}

is.sampling.complete.sub <- function(controller, directory, groups=NULL, chunks=NULL)
{
    if (is.null(chunks))
        chunks = get.chunks.for.groups(controller, groups)
    
    for (chunk in chunks)
    {
        if (!file.exists(results.file(directory, chunk)))
            return (FALSE)
    }
    
    TRUE
}







##------------------------------##
##-- THE RESAMPLING PROCEDURE --##
##------------------------------##

#'@title Do resampling on samples
#'
#'@description Perfoms importance resampling on previously processed samples and caches the results, to prepare for inference by \code{\link{perform.inference.on.resample}}
#'
#'@param directory The directory specified in \code{\link{prepare.distributed.sampling}}
#'@param num.resamples The number of times to resample the original samples
#'@param calculate.likelihood A function which takes as its first argument an object representing a model result (returned by the run.model function passed to prepare.distributed.sampline), and returns a likelihood (scalar or logical) for that result. If the likelihood returns a logical instead of a scalar (ie, a uniform yes or no), then the resample set will contain exactly one copy of each sample for which the likelihood evaluates to True (ie, no stochasticity)
#'@param ... Arguments to be passed to calculate.likelihood and d.input.parameter.prior
#'@param groups The sample groups from which to resample. If passed NULL, will resample from all groups
#'@param ignore.incomplete.samples Logical; if set to FALSE, the function will throw an error if any samples from the specified groups are not complete. If TRUE, then resamples only from those samples that have finished running
#'@param d.input.parameter.prior A way to map a vector of input parameters to their prior density. Can be either (1) an instance of \code{\link{Joint.Canonical.Distribution-class}}, or (2) a function that takes a set of input parameters and returns their joint prior density. Only used if input parameters will be sampled from a distribution different from their prior distribution (ie, if you want to more heavily sample some areas of the parameter space); if input parameters will be sampled according to their priors, then this argument may be omitted
#'@param outfile The file location where the Resamples will be saved (in addition to being returned). By default, saves to 'resamples.Rdata' in the given directory. If passed NULL, the resulting Resamples object will not be saved
#'@param seed Seed for the random number generator
#'
#'@return Returns an instance of \code{\link{Resamples-class}}; also saves the Resamples object into the specified outfile
#'
#'@seealso \code{\link{prepare.distributed.sampling}}\cr
#'\code{\link{augment.distributed.sampling}}\cr
#'\code{\link{perform.inference.on.resample}}
#'
#'@export
resample.distributed.samples <- function(directory,
                                         num.resamples,
                                         calculate.likelihood,
                                         ...,
                                         groups=NULL,
                                         ignore.incomplete.samples=FALSE,
                                         d.input.parameter.prior=NULL,
                                         outfile=file.path(directory, 'resamples.Rdata'),
                                         seed=11111)
{
    rv = do.resample.distributed.samples(directory, num.resamples, calculate.likelihood, ..., 
                                         groups=groups, ignore.incomplete.samples=ignore.incomplete.samples,
                                         d.input.parameter.prior = d.input.parameter.prior, 
                                         outfile=outfile, seed=seed)
    
    invisible(rv)
}

##sets up for resampling, then hands off to a sub-function for the actual work
do.resample.distributed.samples <- function(directory,
                                            num.resamples,
                                            calculate.likelihood,
                                            ...,
                                            groups=NULL,
                                            ignore.incomplete.samples=F,
                                            d.input.parameter.prior=NULL,
                                            outfile,
                                            seed)
{
    controller = load.controller(directory)
    if (!ignore.incomplete.samples && !is.sampling.complete.sub(controller, directory, groups))
        stop(paste0("Cannot perform resampling. Not all the samples have been run."))
    
    if (!is.null(d.input.parameter.prior) && is.null(controller$d.input.parameter.generator))
        stop("Cannot use 'd.input.parameter.prior' unless 'd.input.parameter.generator' has been previously set. You can set it with the function 'set.d.input.parameter.generator")
    
    if (is.null(groups))
        groups = 1:length(controller$groups)
    chunks = get.chunks.for.groups(controller, groups)
    
    if (ignore.incomplete.samples)
    {
        complete.chunks = sapply(chunks, function(chunk){is.sampling.complete.sub(controller, directory, chunks=chunk)})
        chunks = chunks[complete.chunks]
        if (sum(complete.chunks) == 0)
            stop('None of the sampling chunks have been completed; cannot resample')
        else if (sum(complete.chunks) < length(complete.chunks))
        {
            num.incomplete = length(complete.chunks)-sum(complete.chunks)
            print(paste0(num.incomplete, ' out of ', length(chunks), ' (', round(100*num.incomplete/length(chunks), 1), '%) have not completed sampling. These will be left out of the resampling'))
        }
        else
            print(paste0('All ', length(chunks), ' chunks have completed sampling and will be including in the resampling'))
    }
    else if (!is.sampling.complete.sub(controller, directory, chunks=chunks))
        stop('Not all samples have completed sampling')
    
        
    num.samples = sum(sapply(controller$chunks, function(x){any(x==chunks)}))
    if (length(groups)==1)
        groups.text = 'group '
    else
        groups.text = 'groups '
    print(paste0('Loading ', num.samples, ' samples from ', groups.text, paste(groups,collapse=', '), '...'))
    all.results = list()
    for (chunk in chunks)
    {
        loaded = load(results.file(directory, chunk))
        chunk.results = get(loaded[1])
        all.results = c(all.results, chunk.results)
    }
    print('...done loading samples')

    input.parameters = controller$input.parameter.sets[sapply(controller$chunks, function(x){any(x==chunks)}),]
        
    counts.and.max = get.resample.counts(controller, num.resamples, all.results, input.parameters, calculate.likelihood, ..., d.input.parameter.prior = d.input.parameter.prior, seed=seed)
    counts = counts.and.max$sample.counts
    likelihoods = counts.and.max$likelihoods
    max.likelihood = counts.and.max$max.likelihood
    marginal.likelihood = counts.and.max$marginal.likelihood
    
    keep.indices = counts > 0
    
    print('Packaging up resamples...')
 
    kept.params = controller$input.parameter.sets[keep.indices, ]
    if (sum(keep.indices)==1)
        kept.params = t(as.matrix(kept.params))

    resamples = Resamples(results = all.results[keep.indices],
                          likelihoods = likelihoods[keep.indices],
                          input.parameters = kept.params,
                          counts = counts[keep.indices],
                          num.original.samples = num.samples,
                          max.likelihood = max.likelihood,
                          marginal.likelihood = marginal.likelihood)
    
    if (!is.null(outfile))
        save(resamples, file=outfile)
    print('...done packaging resamples')
    
    num.kept = length(resamples@counts)
    pct.kept = round(100*num.kept/num.samples, 2)
    print(paste0('DONE RESAMPLING: ', num.kept, ' of the original ', num.samples, ' (', pct.kept, '%) were included in the resampled subset'))
    
    resamples
}

get.chunks.for.groups <- function(controller, groups)
{
    if (is.null(groups))
        groups = 1:length(controller$groups)
    
    unlist(sapply(controller$groups[groups], function(group){
        group[1]:group[2]
    }))
}

##does the actual resampling
##returns a vector of counts for each resample
get.resample.counts <- function(controller,
                                num.resamples,
                                simulation.results,
                                input.parameters,
                                calculate.likelihood,
                                ...,
                                d.input.parameter.prior,
                                seed)
{
    set.seed(seed)
    
    num.simulations = length(simulation.results)
    weights = numeric(num.simulations)
    
    print(paste0('Calculating likelihood on all ', num.simulations, ' samples...'))
    weights = sapply(simulation.results, calculate.likelihood, ...)
#    for (i in 1:num.simulations)
 #   {
  #      result = simulation.results[[i]]
   #     weights[i] = calculate.likelihood(result, ...)
    #}
    print('...done calculating likelihoods')
    likelihood.is.logical = class(weights) == 'logical'
    
    max.likelihood = max(as.numeric(weights))
    
    if (class(d.input.parameter.prior)=='Joint.Canonical.Distribution')
        d.input.parameter.prior = density.function(d.input.parameter.prior)

    if (!is.null(controller$d.input.parameter.generator) && !is.null(d.input.parameter.prior))
    {
        if (likelihood.is.logical)
            warning('Re-weighting the prior distribution is not done when the likelihood is logical-valued')
        else
        {
            print('Re-weighting samples according to alternative prior (d.input.parameter.prior)...')
            for (i in 1:num.simulations)
                weights[i] = weights[i] * d.input.parameter.prior(input.parametes[i,], ...) / controller$d.input.parameter.generator(input.parameters[i,], ...)
            print('...done re-weighting samples')
        }
    }
    
    marginal.likelihood = mean(as.numeric(weights)) #by sampling theory

    if (likelihood.is.logical)
    {
        print('Including exactly one of each sample in which likelihood is TRUE in resampled set...')    
        sample.counts = as.numeric(weights)
        print('...done resampling')
    }
    else
    {
        print(paste0('Taking ', num.resamples, ' re-samples of the original ', num.simulations, ' samples'))
        sample.counts = resample.likelihoods(weights, num.resamples)
        print('...done resampling')
    }
    
    list(sample.counts = sample.counts, 
         likelihoods = as.numeric(weights),
         max.likelihood = max.likelihood, 
         marginal.likelihood = marginal.likelihood)
}

#'@title Generic resampling function
#'
#'@param likelihoods A vector of likelihoods from which to resample
#'@param n.resamples The number of resamples to take
#'
#'@details Exported because this is a convenient function. However the \code{\link{bayesian.modeling-package}} will handle this internally so the user should not need to call this function directly when using the package
#'
#'@return A vector of integer counts, where rv[i] indicates the number of times that the sample whose likelihood is likelihoods[i] should be included in the resampled set
#'
#'@export
resample.likelihoods <- function(likelihoods, n.resamples)
{
    cum.lik = cumsum(likelihoods)
    lik.max = cum.lik[length(cum.lik)]
    n.samples = length(likelihoods)
    rv = integer(n.samples)
    
    rands = runif(n.resamples, 0, lik.max)
    rands = sort(rands)
    
    sample.index = 1
    for (rand in rands)
    {
        while (cum.lik[sample.index] < rand)
            sample.index = sample.index + 1
        rv[sample.index] = rv[sample.index] + 1
    }
    
    rv
}






##---------------------------------------##
##-- PERFORMING INFERENCE ON RESAMPLES --##
##---------------------------------------##

#'@title Set up inferences on resampled data
#'
#'@description Extracts output parameters from resampled model results, and packages them into a \code{\link{Empiric.Distribution-class}}. May be called multiple times for separate sets of output parameters
#'
#'@param get.output.parameters A function that takes as its first argument an object representing a model result (returned by the run.model function passed to \code{\link{prepare.distributed.sampling}}) and as its second argument a vector of input parameters used to run the model and generate that result. Should return a vector of parameters 'of interest' (ie, the parameters we want to perform inference on)
#'@param ... Arguments to be passed to get.output.parameters
#'@param filter.results (optional) A function that takes as its first argument an object representing a model result (returned by the run.model function passed to \code{\link{prepare.distributed.sampling}}) and as its second argument a vector of input parameters used to run the model and generate that result. Should return TRUE if the given result is to be used for inferences, FALSE if it is to be omitted. If NULL is passed for this argument, all results are used in generating the inference
#'@inheritParams summarize.resample
#'
#'
#'@return An instance of \code{\link{Empiric.Distribution-class}}, whose variables are the output parameters given by get.output.parameters
#'
#'@seealso \code{\link{resample.distributed.sample}}\cr
#'\code{\link{Empiric.Distribution-class}}\cr
#'\code{\link{get.parameters.posterior}}\cr
#'\code{\link{perform.inference.on.resampled.quantiles}}
#'
#'@export
perform.inference.on.resample <- function(resamples,
                                          get.output.parameters,
                                          ...,
                                          filter.results=NULL)
{
    resamples = load.resamples(resamples)
    do.inference.on.resample(resamples, get.output.parameters, ..., filter.results=filter.results)
}

##The work-horse for inference; generates output parameters and bundles them up into an empiric distribution
do.inference.on.resample <- function(resamples,
                                     get.output.parameters,
                                     ...,
                                     filter.results)
{
    if (is.null(filter.results))
    {
        results = resamples@results
        input.parameters = resamples@input.parameters
        counts = resamples@counts
    }
    else
    {
        include = sapply(1:resamples@num.unique.resamples, function(i){
            filter.results(resamples@results[[i]], resamples@input.parameters[i,])
        })
        if (sum(include)==0)
            stop('No results were included by the filter.results function')
        results = resamples@results[include]
        input.parameters = as.matrix(resamples@input.parameters[include,], ncol=ncol(resamples@input.parameters))
        counts = resamples@counts[include]
    }

    output.parameters = sapply(1:length(results), function(i){
        get.output.parameters(results[[i]], input.parameters[i,], ...)
    })
    
    if (is.null(dim(output.parameters)))
    {
        output.parameters = as.matrix(output.parameters, n.col=1)
    }
    else
        output.parameters = t(output.parameters)
    

    Empiric.Distribution(output.parameters, counts)
}

#'@title Perform inferences on a subset of the resampled data (defined by quantiles of an input parameter)
#'
#'@description Like \code{\link{perform.inference.on.resample}}, except that the inference is restricted, for the specified parameters, to just the subset of that parameter that falls within quantile.lower.bound and quantile.upper.bound for each parameter
#'
#'@param parameter The name of the parameter on which to take quantiles
#'@param quantile.lower.bound,quantile.upper.bound The bounds for the quantile to resample within
#'@inheritParams perform.inference.on.resample
#'@inheritParams summarize.resample
#'
#'@return An instance of \code{\link{Empiric.Distribution-class}}, whose variables are the output parameters given by get.output.parameters
#'
#'@seealso \code{\link{perform.inference.on.resample}}\cr
#'\code{\link{Empiric.Distribution-class}}\cr
#'\code{\link{resample.distributed.sample}}
#'
#'@export
perform.inference.on.resampled.quantiles <- function(resamples, get.output.parameters, parameter, quantile.lower.bound, quantile.upper.bound, ...)
{
    cutoffs = quantile(resamples@input.parameters[,parameter], probs=c(quantile.lower.bound, quantile.upper.bound))
    if (cutoffs[2] == 1)
        cutoffs[2] = 1.01
    
    filter = function(results, input.parameters, ...)
    {
        param.val = input.parameters[parameter] 
        param.val >= cutoffs[1] && param.val < cutoffs[2]
    }

    perform.inference.on.resample(resamples, get.output.parameters, ..., filter.results=filter)
}

#'@title Get a matrix of results based on quantile subsets of a resample
#'@return A 4-d array indexed [parameter, ]
#'@export
get.inference.on.resampled.quantiles.matrix <- function(resamples, get.output.parameters, parameters=dimnames(resamples@input.parameters)[[2]], quantile.lower.bounds, quantile.upper.bounds, ..., statistic='mean', interval.coverage=0.95, interval.type='highest-density', smoothed=T, return.as.data.frame=F)
{
    output.names = names(get.output.parameters(resamples@results[[1]], resamples@input.parameters[1,], ...))
    rv=sapply(parameters, function(param){
        sapply(1:length(quantile.lower.bounds), function(i){
            dist = perform.inference.on.resampled.quantiles(resamples, get.output.parameters, param, quantile.lower.bounds[i], quantile.upper.bounds[i], ...)
            rv = get.statistic.and.intervals(dist, statistic=statistic, interval.type=interval.type, coverage=interval.coverage, smoothed=smoothed)
            rv
#            temp = matrix('hi', nrow=nrow(rv), ncol=ncol(rv))
 #           for (row in 1:nrow(temp))
  #          {
   #             for (col in 1:ncol(temp))
    #                temp[row,col] = paste0(param,'-',i,'-',dimnames(rv)[[1]][row], '-', dimnames(rv)[[2]][col])
     #       }
      #      temp
        })
    })
    
    rv = t(rv)
    
    dim(rv) = c(length(parameters), length(output.names), 3, length(quantile.lower.bounds))
    
    if (is.null(names(quantile.lower.bounds)))
        quantile.names = paste0(quantile.lower.bounds,'-',quantile.upper.bounds)
    else
        quantile.names = names(quantile.lower.bounds)
    
    dimnames(rv) = list(parameters, output.names,
                        c(statistic, 'ci.lower', 'ci.upper'),
                        quantile.names)
    
    if (return.as.data.frame)
    {
        df.full = melt(rv, varnames=c('Parameter', 'Output', 'stat', 'Parameter.Quantile'), value.name=statistic)
        df = df.full[df.full$stat==statistic,-3]
        df$ci.lower = df.full[df.full$stat=='ci.lower',statistic]
        df$ci.upper = df.full[df.full$stat=='ci.upper',statistic]
        dimnames(df)[[1]] = 1:dim(df)[1]

        df
    }
    else
        rv
}

##-----------------------------------------------------##
##-- CONVENIENCE FUNCTIONS FOR PRIORS AND POSTERIORS --##
##-----------------------------------------------------##


#'@title Get the Input Parameters used in a Distributed Sample
#'
#'@param directory The directory specified in \code{\link{prepare.distributed.sampling}}
#'@param groups If NULL, all input parameters used in all samples are included Otherwise, only the input parameters used in samples in the specified groups are included
#'
#'@return A matrix where each row represents one set of input parameters passed to one sample
#'
#'@seealso \code{\link{get.parameters.prior}}
#'
#'@export
get.input.parameters <- function(directory, groups=NULL)
{
    controller = load.controller(directory)
    chunks = get.chunks.for.groups(controller, groups)
    chunk.indices = sapply(controller$chunks, function(chunk){
        any(chunk==chunks)
    })
    controller$input.parameter.sets[chunk.indices,]
}


#'@title Get Prior Distribution of Input Parameters
#'
#'@description Gets the empiric prior distribution of the input parameters actually used in generating the samples
#'
#'@inheritParams get.input.parameters
#'
#'@return An instance of a \code{\link{Empiric.Distribution-class}}
#'
#'@seealso \code{\link{get.parameters.posterior}}
#'
#'@export
get.parameters.prior <- function(directory, groups=NULL)
{
    Empiric.Distribution(get.input.parameters(directory, groups))
}

#'@title Get Posterior Distribution of Input Parameters
#'
#'@inheritParams summarize.resample
#'
#'@return An instance of a \code{\link{Empiric.Distribution-class}}
#'
#'@seealso \code{\link{get.parameters.prior}}
#'
#'@export
get.parameters.posterior <- function(resamples)
{
    perform.inference.on.resample(resamples, function(results, params){params})
}

##---------------------------##
##-- WRITING BATCH SCRIPTS --##
##---------------------------##

#'@title Write batch scripts for a distributed sample
#'
#'@description (Re)writes the batch scripts for the distributed sampling that has been setup in <directory>.
#'
#'@param directory The directory that was previously prepared for distributed sampling by a call to \code{\link{prepare.distributed.sampling}}
#'@param rscript.call The code needed to call Rscript (or other code to execute a .R script, like R CMD BATCH). This argument is required. Don't forget to escape backslashes
#'@param rscript.call.postfix Any code that should be included in the batch script after the call to Rscript above. May be NULL
#'@param master.batch.prefix If specified, contains the code to call each wrapper batch script from the main batch script. Don't forget to escape backslashes
#'@param master.batch.postfix If specified, additional code to be included after master.batch.prefix calls each wrapper batch file
#'@param batch.extension The extension for batch files generated by the function
#'@param use.absolute.paths Logical, if true absolute paths are used in batch files so that they may be called from anywhere. Setting this option to true means the batch files will not work if the directory is moved
#'
#'@details In general, the batch scripts may be in one of two forms:\itemize{
#'\item In the simpler method, the main batch script directly calls Rscript multiple times to execute the .R script that actually runs a sample through the model. This is achieved by specifying the rscript.call argument, but passing NULL for the master.batch.prefix argument
#'\item In the more complicated, or 'nested' method, two sets of batch scripts are created. The main batch script calls a 'wrapper' batch script for each separate execution of the .R script. In this case, master.batch.prefix and master.batch.postfix are used to specify how the master batch file calls each wrapper batch file, and rscript.call / rscript.call.postfix are used in each wrapper batch file to actually call the .R script
#'}
#'Generally, the second method will be preferred, as it is useful for queueing tasks on a remote machine.\cr
#'Either way, a master batch file 'run_all' is created in the specified directory that, when called, will execute all the individual samples
#'
#'@examples
#'# Using the nested method to set up distributed running of the samples with qsub
#'# (assuming we have already set up a distributed sampling procedure
#'#  with a call to prepare.distributed.sampling
#'
#'write.batch.scripts('mydirectory',
#'                    rscript.call='Rscript',
#'                    master.batch.prefix="qsub -l mem_free=10G")
#'
#'# qsub is a command for queueing a task on a cluster; in this case, 
#'# we specify that the job should be queued to a machine with at 
#'# least 10G of memory free
#'
#'@export
write.batch.scripts <- function(directory,
                                rscript.call='Rscript', 
                                rscript.call.postfix = NULL, 
                                master.batch.prefix = NULL, 
                                master.batch.postfix = NULL, 
                                batch.extension = 'sh',
                                use.absolute.paths = TRUE)
{
    do.save.batch.info.and.write.scripts(directory,
                                         rscript.call, rscript.call.postfix, 
                                         master.batch.prefix, master.batch.postfix, 
                                         batch.extension,
                                         use.absolute.paths)
    
    print(paste0("Batch files have been written to the directory '", directory, "':"))
    do.print.batch.summary(load.controller(directory), groups=groups)
}

#saves the new info to the controller and writes the batch scripts
do.save.batch.info.and.write.scripts <- function(directory,
                                                 rscript.call, rscript.call.postfix, 
                                                 master.batch.prefix, master.batch.postfix, 
                                                 batch.extension,
                                                 use.absolute.paths)
{
    controller = load.controller(directory)
    
    if (is.empty(master.batch.prefix))
    {
        controller$main.batch.prefix = rscript.call
        controller$main.batch.postfix = rscript.call.postfix
        controller$batch.wrapper.prefix = NULL
        controller$batch.wrapper.postfix = NULL
    }
    else
    {
        controller$main.batch.prefix = master.batch.prefix
        controller$main.batch.postfix = master.batch.postfix
        controller$batch.wrapper.prefix = rscript.call
        controller$batck.wrapper.postfix = rscript.call.postfix
    }
    
    controller$batch.extension = if (substr(batch.extension,1,1)=='.') batch.extension else paste0('.', batch.extension)
    
    save.controller(controller, directory)
    
    groups = 1:length(controller$groups)
    do.write.batch.scripts(controller, directory,groups=groups)
}

#writes the main (finished and unfinished) batch scripts,
# as well as the group batch scripts for each group given
do.write.batch.scripts <- function(controller, directory, groups)
{
    #write out our batch files
    write.main.batch.file(controller, directory, group=NULL, overwrite=T)
    write.main.batch.file(controller, directory, group=NULL, overwrite=F)
    
    for (group in groups)
        write.main.batch.file(controller, directory, group=group, overwrite=T)
}

do.print.batch.summary <- function(controller, show.all=T, show.unfinished=T, groups=NULL, print.spacer=T)
{
    if (print.spacer)
        print("----------------------------------------------------------------")
    
    if (show.all)
        print(paste0("Use 'run_all", controller$batch.extension, "' to execute scripts to run all the samples in a distributed fashion"))
    
    if (show.unfinished)
        print(paste0("Use 'run_unfinished", controller$batch.extension, "' to execute scripts to run only the samples that have not already been run (in a distributed fashion)"))
    
    if (!is.null(groups))
    {
        for (group in groups)
            print(paste0("Use 'run_", group, controller$batch.extension, "' to execute scripts to run only the samples that were added by this function call (in a distributed fashion)"))
    }
}




#'@title Run previously set up distributed samples from the consoles
#'
#'@description A method to run distributed samples from the R console (instead of by batch scripts)
#'
#'@param groups, chunks The groups and/or chunks from which samples are to be run. If both are NA, all samples will be run
#'@inheritParams write.batch.scripts
#'
#'@details Calls the function 'run.model' specified in the call to \code{\link{prepare.distributed.sampling}} on each of the input parameters representing a sample.
#'Note that running samples this way does not allow them to be run in parallel
#'
#'@value No return value
#'
#'@export
run.distributed.samples <- function(directory, groups=NA, chunks=NA)
{
    controller = load.controller(directory)
    
    if (is.na(chunks))
        chunks = numeric()
    if (!is.na(groups))
        chunks = c(chunks, get.chunks.for.groups(controller, groups))
    if (length(chunks)==0)
        chunks = 1:controller$num.chunks
    
    sapply(chunks, function(chunk){
        do.run.distributed.sample(directory, chunk, overwrite=T, controller=controller)
    })
    
    invisible(NULL)
}

delete.distributed.sampling <- function(directory, delete.directory=T)
{
    
}

#'@title Reset a directory for distributed sampling
#'
#'@description Clears all previously run samples from a directory set up for distributed sampling
#'
#'@inheritParams write.batch.scripts
#'
#'@value 0 for success, 1 for failure, invisibly, as in \code{\link{unlink}}
#'
#'@export
reset.distributed.sampling <- function(directory)
{
    result = unlink(results.directory(directory), recursive = T)
    if (result==0)
        dir.create(results.directory(directory))
    
    invisible(result)
}




##--------------------------------------------------##
##-- EXPORTED FUNCTION TO RUN SAMPLES FROM SCRIPT --##
##--------------------------------------------------##

#'@title Run a (previously prepared) set of samples
#'
#'@description This function is exported so that the scripts which actually run samples can call it. However, there is no need for a user to call this function directly as long as they are using the prepared batch scripts
#'
#'@param directory The directory holding all the information
#'@param chunk The chunk number to run
#'@param overwrite Logical indicating whether to overwrite previously saved results
#'@param controller The controller object if already loaded (if NULL, will be loaded from directory)
#'
#'@export 
do.run.distributed.sample <- function(directory, chunk, overwrite=T, controller=NULL)
{
    file = results.file(directory, chunk)
    if (overwrite || !file.exists(file))
    {
        if (is.null(controller))
            controller = load.controller(directory)
        sapply(controller$files.to.source, source)
        
        input.parameter.sets = controller$input.parameter.sets[controller$chunks==chunk,]
        if (is.null(dim(input.parameter.sets)))
            input.parameter.sets = t(as.matrix(input.parameter.sets))
        num.samples = dim(input.parameter.sets)[1]
        
        print(paste0('Running model on ', num.samples, ' samples...'))
        results = list()
        for (i in 1:num.samples)
        {
            print(paste0('   -Running model on sample ', i, ' of ', num.samples))
            results[[i]] = do.call(controller$run.model, c(list(input.parameter.sets[i,]), controller$dotdotdot))
        }
        print('...done running model on all samples')
        
        save(results, file=file)
    }
}






##------------------------------##
##-- LOW-LEVEL FILE FUNCTIONS --##
##------------------------------##

load.controller <- function(directory)
{
    loaded = load(file.path(directory, 'controller.Rdata'))
    get(loaded[1])
}

save.controller <- function(controller, directory)
{
    if (!file.exists(directory))
        dir.create(directory)
    
    if (!is.null(controller$batch.wrapper.prefix) && !file.exists(file.path(directory, 'wrappers')))
        dir.create(file.path(directory, 'wrappers'))
    
    if (!file.exists(file.path(directory, 'results')))
        dir.create(file.path(directory, 'results'))
    
    save(controller, file=file.path(directory, 'controller.Rdata'))
}

results.file <- function(directory, chunk)
{
    file.path(directory, 'results', paste0('results',chunk,'.Rdata'))
}

results.directory <- function(directory)
{
    file.path(directory, 'results')
}

#'@export
load.resamples <- function(resamples)
{
    if (class(resamples)=='Resamples')
        return (resamples)
    
    if (dir.exists(resamples))
        loaded = load(file.path(resamples, 'resamples.Rdata'))
    else
        loaded = load(resamples)
    
    
    get(loaded[1])
}


write.main.batch.file <- function(controller, directory, group=NULL, overwrite=T)
{
    if (is.null(group))
    {
        if (overwrite)
            batch.out = file.path(directory, paste0('run_all', controller$batch.extension))
        else
            batch.out = file.path(directory, paste0("run_unfinished", controller$batch.extension))
        
        chunks = 1:controller$num.chunks
    }
    else
    {
        batch.out = file.path(directory, paste0('run_', group, controller$batch.extension))

        group.indices = controller$groups[[group]]
        chunks = group.indices[1]:group.indices[2]
        
        if (!is.null(controller$batch.wrapper.prefix))
            write.batch.wrappers(controller, directory, chunks)
    }
    
    if (is.null(controller$batch.wrapper.prefix))
    {
        script.path = get.path(controller, directory, 'run_script.R')
        chunk.calls = paste0('"', script.path, '" ', chunks, ' ', as.character(overwrite))
    }
    else
        chunk.calls = paste0('"', sapply(chunks, batch.wrapper.filename, controller, directory, overwrite), '"')
    
    
    script.calls = paste0('"', controller$main.batch.prefix, '" ', chunk.calls)
    
    if (!is.null(controller$main.batch.postfix))
        script.calls = paste(script.calls, ' ', controller$main.batch.postfix)
    
    
    cat(paste0(script.calls, '\n'),
        sep='', file=batch.out)
}

write.batch.wrappers <- function(controller, directory, chunks)
{
    for (chunk in chunks)
    {
        write.batch.wrapper.file(controller, directory, chunk, T)
        write.batch.wrapper.file(controller, directory, chunk, F)
    }
}

write.batch.wrapper.file <- function(controller, directory, chunk, overwrite)
{
    script.path = get.path(controller, directory, 'run_script.R')
    script.call = paste0(controller$batch.wrapper.prefix, ' "', script.path, '" ', chunk, ' ', as.character(overwrite))
    if (!is.null(controller$batch.wrapper.postfix))
        script.calls = paste(script.calls, ' "', controller$batch.wrapper.postfix, '"')
    
    cat(script.call, sep='', file=batch.wrapper.filename(chunk, controller, directory, overwrite))
}

batch.wrapper.filename <- function(chunk, controller, directory, overwrite)
{
    if (overwrite)
        o_suffix = '_o'
    else
        o_suffix = ''
    
    get.path(controller, directory, 'wrappers', paste0('run_chunk',chunk,o_suffix,controller$batch.extension))
}

write.script <- function(controller, directory)
{
    dirload = paste0("directory='",get.path(controller, directory),"'")
    dirload = gsub("([\\])","\\\\\\\\", dirload) 
    cat("args = commandArgs(trailingOnly=TRUE)
if (length(args) < 1)
    stop('A chunk number must be supplied to this script')
chunk = as.integer(args[1])

if (length(args) < 2) overwrite=T else overwrite=as.logical(args[2])
        
library(bayesian.modeling)",
        dirload,
        "\ndo.run.distributed.sample(directory, chunk, overwrite)", 
        fill=TRUE, sep='', file=get.path(controller, directory, 'run_script.R'))
}

get.path <- function(controller, ...)
{
    if (controller$use.absolute.paths)
        file.path(getwd(), ...)
    else
        file.path(...)
}




##-----------------------------##
##-- OTHER LOW-LEVEL HELPERS --##
##-----------------------------##

is.empty <- function(obj)
{
    is.null(obj) || is.na(obj) || obj==''
}

#returns a vector where rv[i] is the number of chunks in group i
num.chunks.per.group <- function(controller)
{
    sapply(controller$groups, function(x){
        x[2]-x[1] + 1
    })
}

#to help with printing summaries
#rv[i] is the number of chunks completed in each group
get.num.complete.per.group <- function(controller, directory)
{
    sapply(controller$groups, function(x){
        count = 0
        for (chunk in x[1]:x[2])
        {
            if (file.exists(results.file(directory, chunk)))
                count = count + 1
        }
        count
    })
}